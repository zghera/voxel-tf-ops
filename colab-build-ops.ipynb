{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "terminal.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ANF6EJEiHjA-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2KcG9-CzEPb",
        "outputId": "915b74b7-39a3-4a7a-8e58-fd51639de6ff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/root/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /root/gdrive; to attempt to forcibly remount, call drive.mount(\"/root/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve7QJDAXUdUb",
        "outputId": "65bf7ff7-a3d5-49ba-ee09-4847c46549fc"
      },
      "source": [
        "%cd ~/gdrive/MyDrive/'_ECE 570'/Project/ops/voxel-tf-ops/\n",
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/gdrive/MyDrive/_ECE 570/Project/ops/voxel-tf-ops\n",
            "\u001b[0m\u001b[01;34mavg_vox\u001b[0m/          \u001b[01;34mcuda_includes\u001b[0m/  MANIFEST.in     \u001b[01;34mtf\u001b[0m/               WORKSPACE\n",
            "BUILD             \u001b[01;34mgpu\u001b[0m/            README.md       \u001b[01;34mthird_party\u001b[0m/\n",
            "build_pip_pkg.sh  LICENSE         setup.py        \u001b[01;34mtrilinear_devox\u001b[0m/\n",
            "configure.sh      Makefile        terminal.ipynb  \u001b[01;34mutils\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHuroIww-eJN"
      },
      "source": [
        "!mkdir -p /usr/local/lib/python3.7/dist-packages/tensorflow/include/third_party/gpus/cuda/include"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2bcgd7F_zUr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2dcabb0-b399-4820-b3a0-19f6d01f26fb"
      },
      "source": [
        "!cp -r cuda_includes/*.h /usr/local/lib/python3.7/dist-packages/tensorflow/include/third_party/gpus/cuda/include\n",
        "!ls /usr/local/lib/python3.7/dist-packages/tensorflow/include/third_party/gpus/cuda/include"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda_fp16.h  cuda.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czas9e_D1B4s"
      },
      "source": [
        "# TF 2.7 had 3 errors in tensor_types.h, downgraded to TF 2.6 and works!\n",
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==2.6.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEolzIGf4-Yy",
        "outputId": "c3c72140-e90c-4aca-a522-6874eee7eae7"
      },
      "source": [
        "!python3 -c 'import tensorflow as tf; print(tf.__version__)' "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWMgSrz6JlT9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b70d3b8-d215-4e76-f583-161b476e57e1"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# tf.debugging.set_log_device_placement(True)\n",
        "gpu_devices = tf.config.list_physical_devices('GPU')\n",
        "print(\"Num GPUs Available: \", len(gpu_devices))\n",
        "for device in gpu_devices:\n",
        "    tf.config.experimental.set_memory_growth(device, True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANF6EJEiHjA-"
      },
      "source": [
        "# Voxelization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8N3gAPMU6kV"
      },
      "source": [
        "!make clean_vox"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mA1YTUEvQe8",
        "outputId": "bc4837ff-a329-48c9-9360-3ef4653faee0"
      },
      "source": [
        "from tensorflow.python.framework.errors_impl import NotFoundError\n",
        "\n",
        "avg_vox_ops_so_path = './avg_vox/python/ops/_avg_vox_ops.so'\n",
        "try:\n",
        "  avg_vox_ops = tf.load_op_library(avg_vox_ops_so_path)\n",
        "except NotFoundError as e:\n",
        "  print('Successfully cleaned!')\n",
        "else:\n",
        "  print('Colab is still seeing old .so')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab is still seeing old .so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld9LoOKx9UAW"
      },
      "source": [
        "!make vox_gpu_only"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlbgtyT083xO"
      },
      "source": [
        "!make vox_op"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO-tZxXICcAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2ad6b8a-081c-4c09-d6f7-978bba424d44"
      },
      "source": [
        "!make vox_test"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python avg_vox/python/ops/avg_vox_ops_test.py\n",
            "2021-11-15 02:49:09.828454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-15 02:49:09.836988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-15 02:49:09.837842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "Running tests under Python 3.7.12: /usr/bin/python3\n",
            "[ RUN      ] AvgVoxTest.test_avg_voxelize_forward\n",
            "2021-11-15 02:49:09.841346: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-11-15 02:49:09.841571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-15 02:49:09.842151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-15 02:49:09.842683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-15 02:49:10.523143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-15 02:49:10.523749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-15 02:49:10.524333: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-15 02:49:10.524845: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-11-15 02:49:10.524908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15030 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "INFO:tensorflow:time(__main__.AvgVoxTest.test_avg_voxelize_forward): 0.69s\n",
            "I1115 02:49:10.532760 139689236989824 test_util.py:2189] time(__main__.AvgVoxTest.test_avg_voxelize_forward): 0.69s\n",
            "[       OK ] AvgVoxTest.test_avg_voxelize_forward\n",
            "[ RUN      ] AvgVoxTest.test_avg_voxelize_gradients\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "W1115 02:49:10.671152 139689236989824 backprop.py:1047] Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "INFO:tensorflow:time(__main__.AvgVoxTest.test_avg_voxelize_gradients): 0.14s\n",
            "I1115 02:49:10.675028 139689236989824 test_util.py:2189] time(__main__.AvgVoxTest.test_avg_voxelize_gradients): 0.14s\n",
            "[       OK ] AvgVoxTest.test_avg_voxelize_gradients\n",
            "[ RUN      ] AvgVoxTest.test_session\n",
            "[  SKIPPED ] AvgVoxTest.test_session\n",
            "----------------------------------------------------------------------\n",
            "Ran 3 tests in 0.835s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtyqA7l4Hq64"
      },
      "source": [
        "# from avg_vox.python.ops.avg_vox_ops import avg_voxelize_forward\n",
        "\n",
        "avg_vox_ops = tf.load_op_library(avg_vox_ops_so_path)\n",
        "# avg_vox_ops = tf.load_op_library('/root/gdrive/My Drive/_ECE 570/Project/ops/voxel-tf-ops/avg_vox/python/ops/_avg_vox_ops.so')\n",
        "avg_voxelize_forward = avg_vox_ops.avg_vox_forward\n",
        "avg_voxelize_backward = avg_vox_ops.avg_vox_backward"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJa1HmZ7t283"
      },
      "source": [
        " Note: We only see 1, and 2, 3 in `out` because of the \"clipping\" that was\n",
        "       added in GridStatsKernel. More specifically, the equation for\n",
        "       calculating a point's voxel index may give a voxel index greater\n",
        "       than R**3 (point (4,4,4) in this case). If that occurs, we do not\n",
        "       increment the element in `cnt` corresponding to that voxel. Thus, we\n",
        "       do not see the corresponding feature for that point in `out`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bffxjhrDXUW",
        "outputId": "fb217844-4e89-4f9a-aa2a-6ab4ed0a773a"
      },
      "source": [
        "###################\n",
        "# Setup Constants #\n",
        "###################\n",
        "B = 2\n",
        "C = 5\n",
        "N = 4\n",
        "R = 5\n",
        "\n",
        "# [B, C, N] = [2, 5, 4]\n",
        "features = tf.constant([[[1, 2, 3, 4]]], dtype=tf.float32)\n",
        "features = tf.repeat(tf.repeat(features, 5, axis=1), 2, axis=0)\n",
        "\n",
        "# [B, 3, N] = [2, 3, 4]\n",
        "coords = tf.constant([[[1, 2, 3, 4]]], dtype=tf.int32)\n",
        "coords = tf.repeat(tf.repeat(coords, 3, axis=1), 2, axis=0)\n",
        "\n",
        "resolution = tf.constant(R)\n",
        "\n",
        "##################\n",
        "# Call Operation #\n",
        "##################\n",
        "out, ind, cnt = avg_voxelize_forward(features, coords, resolution)\n",
        "\n",
        "#################################################\n",
        "# Get Gradients of Arbitrary Loss WRT Op Output #\n",
        "#################################################\n",
        "mse = tf.keras.losses.MeanSquaredError()\n",
        "ones_label = tf.ones(shape=[B, C, R**3])\n",
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(out)\n",
        "  loss = mse(ones_label, out)\n",
        "  dL_dout = tape.gradient(loss, out)\n",
        "\n",
        "####################################################\n",
        "# Get Gradients of Loss WRT `features` input of Op #\n",
        "####################################################\n",
        "features_grad = avg_voxelize_backward(dL_dout, ind, cnt)\n",
        "\n",
        "#####################\n",
        "# Print Out Tensors #\n",
        "#####################\n",
        "print(\"\\n\\n--------- Forward ---------\\n\")\n",
        "\n",
        "print(\"\\nind\\n---\")\n",
        "print(ind)\n",
        "print()\n",
        "\n",
        "print(\"cnt\\n---\")\n",
        "print(cnt)\n",
        "print()\n",
        "\n",
        "print(\"out\\n---\")\n",
        "print(out)\n",
        "print()\n",
        "\n",
        "print(\"--------- Backward ---------\\n\")\n",
        "\n",
        "print(\"dL/dout\\n------\")\n",
        "print(dL_dout)\n",
        "print()\n",
        "\n",
        "print(\"features graient\\n----------------\")\n",
        "print(features_grad)\n",
        "print(\"\\n\")\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--------- Forward ---------\n",
            "\n",
            "\n",
            "ind\n",
            "---\n",
            "tf.Tensor(\n",
            "[[ 31  62  93 124]\n",
            " [ 31  62  93 124]], shape=(2, 4), dtype=int32)\n",
            "\n",
            "cnt\n",
            "---\n",
            "tf.Tensor(\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]], shape=(2, 125), dtype=int32)\n",
            "\n",
            "out\n",
            "---\n",
            "tf.Tensor(\n",
            "[[[0. 0. 0. ... 0. 0. 4.]\n",
            "  [0. 0. 0. ... 0. 0. 4.]\n",
            "  [0. 0. 0. ... 0. 0. 4.]\n",
            "  [0. 0. 0. ... 0. 0. 4.]\n",
            "  [0. 0. 0. ... 0. 0. 4.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 4.]\n",
            "  [0. 0. 0. ... 0. 0. 4.]\n",
            "  [0. 0. 0. ... 0. 0. 4.]\n",
            "  [0. 0. 0. ... 0. 0. 4.]\n",
            "  [0. 0. 0. ... 0. 0. 4.]]], shape=(2, 5, 125), dtype=float32)\n",
            "\n",
            "--------- Backward ---------\n",
            "\n",
            "dL/dout\n",
            "------\n",
            "tf.Tensor(\n",
            "[[[-0.0016 -0.0016 -0.0016 ... -0.0016 -0.0016  0.0048]\n",
            "  [-0.0016 -0.0016 -0.0016 ... -0.0016 -0.0016  0.0048]\n",
            "  [-0.0016 -0.0016 -0.0016 ... -0.0016 -0.0016  0.0048]\n",
            "  [-0.0016 -0.0016 -0.0016 ... -0.0016 -0.0016  0.0048]\n",
            "  [-0.0016 -0.0016 -0.0016 ... -0.0016 -0.0016  0.0048]]\n",
            "\n",
            " [[-0.0016 -0.0016 -0.0016 ... -0.0016 -0.0016  0.0048]\n",
            "  [-0.0016 -0.0016 -0.0016 ... -0.0016 -0.0016  0.0048]\n",
            "  [-0.0016 -0.0016 -0.0016 ... -0.0016 -0.0016  0.0048]\n",
            "  [-0.0016 -0.0016 -0.0016 ... -0.0016 -0.0016  0.0048]\n",
            "  [-0.0016 -0.0016 -0.0016 ... -0.0016 -0.0016  0.0048]]], shape=(2, 5, 125), dtype=float32)\n",
            "\n",
            "features graient\n",
            "----------------\n",
            "tf.Tensor(\n",
            "[[[0.     0.0016 0.0032 0.0048]\n",
            "  [0.     0.0016 0.0032 0.0048]\n",
            "  [0.     0.0016 0.0032 0.0048]\n",
            "  [0.     0.0016 0.0032 0.0048]\n",
            "  [0.     0.0016 0.0032 0.0048]]\n",
            "\n",
            " [[0.     0.0016 0.0032 0.0048]\n",
            "  [0.     0.0016 0.0032 0.0048]\n",
            "  [0.     0.0016 0.0032 0.0048]\n",
            "  [0.     0.0016 0.0032 0.0048]\n",
            "  [0.     0.0016 0.0032 0.0048]]], shape=(2, 5, 4), dtype=float32)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z57QynhwHo71"
      },
      "source": [
        "# Devoxelization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9muQn6zFU9tX",
        "outputId": "a4019bd9-513f-4c62-b09b-e8690e108a80"
      },
      "source": [
        "!make clean_devox"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm -f trilinear_devox/python/ops/_trilinear_devox_ops.cu.o trilinear_devox/python/ops/_trilinear_devox_ops.so \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpC9n6PSH3pP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a49b607-4081-4c43-a4ff-59be4e62239c"
      },
      "source": [
        "from tensorflow.python.framework.errors_impl import NotFoundError\n",
        "\n",
        "trilinear_devox_ops_so_path = './trilinear_devox/python/ops/_trilinear_devox_ops.so'\n",
        "try:\n",
        "  trilinear_devox_ops = tf.load_op_library(trilinear_devox_ops_so_path)\n",
        "except NotFoundError as e:\n",
        "  print('Successfully cleaned!')\n",
        "else:\n",
        "  print('Colab is still seeing old .so')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully cleaned!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3kHkwWEH3pQ"
      },
      "source": [
        "!make devox_gpu_only"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvz3AM4dH3pQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7205a5a0-41e3-47c7-f559-ad328b6f4bfa"
      },
      "source": [
        "!make devox_op"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc -std=c++11 -c -o trilinear_devox/python/ops/_trilinear_devox_ops.cu.o trilinear_devox/cc/trilinear_devox_kernels.cu.cc  -I/usr/local/lib/python3.7/dist-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0 -DEIGEN_MAX_ALIGN_BYTES=64 -Iutils -D GOOGLE_CUDA=1 -x cu -Xcompiler -fPIC -DNDEBUG --expt-relaxed-constexpr\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/include/absl/strings/string_view.h(337): warning: expression has no effect\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/include/absl/strings/string_view.h(347): warning: expression has no effect\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/include/absl/strings/string_view.h(529): warning: expression has no effect\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/include/tensorflow/core/platform/file_system.h(574): warning: overloaded virtual function \"tensorflow::FileSystem::FilesExist\" is only partially overridden in class \"tensorflow::WrappedFileSystem\"\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/include/tensorflow/core/platform/file_system.h(574): warning: overloaded virtual function \"tensorflow::FileSystem::CreateDir\" is only partially overridden in class \"tensorflow::WrappedFileSystem\"\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/include/tensorflow/core/platform/env.h(495): warning: overloaded virtual function \"tensorflow::Env::RegisterFileSystem\" is only partially overridden in class \"tensorflow::EnvWrapper\"\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/include/absl/types/optional.h(428): warning: expression has no effect\n",
            "          detected during instantiation of \"const T &absl::lts_20210324::optional<T>::operator*() const & [with T=stream_executor::dnn::AlgorithmDesc]\" \n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/include/tensorflow/stream_executor/dnn.h(817): here\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/include/absl/types/optional.h(428): warning: expression has no effect\n",
            "          detected during:\n",
            "            instantiation of \"const T &absl::lts_20210324::optional<T>::operator*() const & [with T=size_t]\" \n",
            "(605): here\n",
            "            instantiation of \"auto absl::lts_20210324::operator==(const absl::lts_20210324::optional<T> &, const absl::lts_20210324::optional<U> &)->__nv_bool [with T=size_t, U=size_t]\" \n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/include/tensorflow/stream_executor/dnn.h(876): here\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/include/absl/strings/string_view.h(337): warning: expression has no effect\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/include/absl/strings/string_view.h(347): warning: expression has no effect\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/include/absl/strings/string_view.h(529): warning: expression has no effect\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/include/tensorflow/core/platform/file_system.h(574): warning: overloaded virtual function \"tensorflow::FileSystem::FilesExist\" is only partially overridden in class \"tensorflow::WrappedFileSystem\"\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/include/tensorflow/core/platform/file_system.h(574): warning: overloaded virtual function \"tensorflow::FileSystem::CreateDir\" is only partially overridden in class \"tensorflow::WrappedFileSystem\"\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/include/tensorflow/core/platform/env.h(495): warning: overloaded virtual function \"tensorflow::Env::RegisterFileSystem\" is only partially overridden in class \"tensorflow::EnvWrapper\"\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/include/absl/types/optional.h(428): warning: expression has no effect\n",
            "          detected during instantiation of \"const T &absl::lts_20210324::optional<T>::operator*() const & [with T=stream_executor::dnn::AlgorithmDesc]\" \n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/include/tensorflow/stream_executor/dnn.h(817): here\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/include/absl/types/optional.h(428): warning: expression has no effect\n",
            "          detected during:\n",
            "            instantiation of \"const T &absl::lts_20210324::optional<T>::operator*() const & [with T=size_t]\" \n",
            "(605): here\n",
            "            instantiation of \"auto absl::lts_20210324::operator==(const absl::lts_20210324::optional<T> &, const absl::lts_20210324::optional<U> &)->bool [with T=size_t, U=size_t]\" \n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/include/tensorflow/stream_executor/dnn.h(876): here\n",
            "\n",
            "g++ -I/usr/local/lib/python3.7/dist-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0 -DEIGEN_MAX_ALIGN_BYTES=64 -fPIC -O2 -std=c++11 -o trilinear_devox/python/ops/_trilinear_devox_ops.so trilinear_devox/cc/trilinear_devox_kernels.cc trilinear_devox/python/ops/_trilinear_devox_ops.cu.o -shared -L/usr/local/lib/python3.7/dist-packages/tensorflow -l:libtensorflow_framework.so.2  -D GOOGLE_CUDA=1  -I/usr/local/cuda/targets/x86_64-linux/include -L/usr/local/cuda/targets/x86_64-linux/lib -lcudart\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIzC2XEtH3pQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c7836d-08dd-485e-85c8-3d83b7c8f7a7"
      },
      "source": [
        "!make devox_test"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python trilinear_devox/python/ops/trilinear_devox_ops_test.py\n",
            "2021-11-15 03:35:27.202285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-15 03:35:27.211007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-15 03:35:27.211589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "Running tests under Python 3.7.12: /usr/bin/python3\n",
            "[ RUN      ] TrilinearDevoxTest.test_session\n",
            "[  SKIPPED ] TrilinearDevoxTest.test_session\n",
            "[ RUN      ] TrilinearDevoxTest.test_trilinear_devoxelize_forward\n",
            "2021-11-15 03:35:27.215080: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-11-15 03:35:27.215304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-15 03:35:27.215877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-15 03:35:27.216407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-15 03:35:27.905428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-15 03:35:27.906067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-15 03:35:27.906620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-15 03:35:27.907135: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-11-15 03:35:27.907191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15030 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "INFO:tensorflow:time(__main__.TrilinearDevoxTest.test_trilinear_devoxelize_forward): 0.71s\n",
            "I1115 03:35:27.926937 139693592840064 test_util.py:2189] time(__main__.TrilinearDevoxTest.test_trilinear_devoxelize_forward): 0.71s\n",
            "[       OK ] TrilinearDevoxTest.test_trilinear_devoxelize_forward\n",
            "[ RUN      ] TrilinearDevoxTest.test_trilinear_devoxelize_gradients\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "W1115 03:35:28.069478 139693592840064 backprop.py:1047] Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "INFO:tensorflow:time(__main__.TrilinearDevoxTest.test_trilinear_devoxelize_gradients): 0.15s\n",
            "I1115 03:35:28.073314 139693592840064 test_util.py:2189] time(__main__.TrilinearDevoxTest.test_trilinear_devoxelize_gradients): 0.15s\n",
            "[       OK ] TrilinearDevoxTest.test_trilinear_devoxelize_gradients\n",
            "----------------------------------------------------------------------\n",
            "Ran 3 tests in 0.859s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iirwbxoqH3pR"
      },
      "source": [
        "# from avg_vox.python.ops.avg_vox_ops import avg_voxelize_forward\n",
        "\n",
        "trilinear_devox_ops = tf.load_op_library(trilinear_devox_ops_so_path)\n",
        "# trilinear_devox_ops = tf.load_op_library('/root/gdrive/My Drive/_ECE 570/Project/ops/voxel-tf-ops/trilinear_devox/python/ops/_trilinear_devox_ops.so')\n",
        "trilinear_devoxelize_forward = trilinear_devox_ops.trilinear_devox_forward\n",
        "trilinear_devoxelize_backward = trilinear_devox_ops.trilinear_devox_backward"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuhckIs2tdbM"
      },
      "source": [
        "Note: We use R=5 rather than R=4 like in the avg_vox tests because of an\n",
        "      issue in the backwards output (gradients of features/input). \n",
        "\n",
        "For the forward pass, the output is as expected (see below).\n",
        "Note that we see 0 rather than 4 (i.e. expected_outs=[[[1,2,3,4]], ...], ...])\n",
        "in `outs` because of the \"clipping\" when creating `cnt`. For more\n",
        "information, see avg_vox/cc/avg_vox_kernels.cu.cc|GridStatsKernel \n",
        "or the avg_vox tests.\n",
        "\n",
        "However, for the backwards pass, there was an inconsistency in the\n",
        "1st channel of the 1st batch where all channels of each batch should\n",
        "have the exact same R**3 values. For more detail, see the following\n",
        "code block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYnrTjRTY2N4",
        "outputId": "f4f666b7-245a-4e60-8cb1-bcf059857d47"
      },
      "source": [
        "###################\n",
        "# Setup Constants #\n",
        "###################\n",
        "B = 2\n",
        "C = 5\n",
        "N = 4\n",
        "# Note: We use R=5 rather than R=4 like in the avg_vox tests because of an\n",
        "#       issue in the backwards output (gradients of features/input). \n",
        "#\n",
        "#       For the forward pass, the output is as expected (see below).\n",
        "#       Note that we see 0 rather than 4 (i.e. expected_outs=[[[1,2,3,4]]]])\n",
        "#       in `outs` because of the \"clipping\" when creating `cnt`. For more\n",
        "#       information, see avg_vox/cc/avg_vox_kernels.cu.cc|GridStatsKernel \n",
        "#       or the avg_vox tests.\n",
        "#\n",
        "#       However, for the backwards pass, there was an inconsistency in the\n",
        "#       1st channel of the 1st batch where all channels of each batch should\n",
        "#       have the exact same R**3 values. For more detail, see the following\n",
        "#       code block.\n",
        "R = 5 #4\n",
        "\n",
        "# [B, C, R**3] = [2, 5, 64]\n",
        "# features = tf.constant([[\n",
        "#   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
        "#    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0,\n",
        "#    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3,]\n",
        "#   ]], dtype=tf.float32)\n",
        "# features = tf.repeat(tf.repeat(features, 5, axis=1), 2, axis=0)\n",
        "# [B, C, R**3] = [2, 5, 125]\n",
        "features = tf.constant([[\n",
        " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "  0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0,\n",
        "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "  0, 0, 0, 0, 4]\n",
        " ]], dtype=tf.float32)\n",
        "features = tf.repeat(tf.repeat(features, 5, axis=1), 2, axis=0)\n",
        "\n",
        "# [B, 3, N] = [2, 3, 4]\n",
        "coords = tf.constant([[[1, 2, 3, 4]]], dtype=tf.float32)\n",
        "coords = tf.repeat(tf.repeat(coords, 3, axis=1), 2, axis=0)\n",
        "\n",
        "# Attrs\n",
        "resolution = tf.constant(R)\n",
        "is_training = True\n",
        "\n",
        "##################\n",
        "# Call Operation #\n",
        "##################\n",
        "outs, inds, wgts = trilinear_devoxelize_forward(features, coords, resolution, is_training)\n",
        "\n",
        "#################################################\n",
        "# Get Gradients of Arbitrary Loss WRT Op Output #\n",
        "#################################################\n",
        "import time\n",
        "time.sleep(1)\n",
        "mse = tf.keras.losses.MeanSquaredError()\n",
        "ones_label = tf.ones(shape=[B, C, N])\n",
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(outs)\n",
        "  loss = mse(ones_label, outs)\n",
        "  dL_dout = tape.gradient(loss, outs)\n",
        "\n",
        "####################################################\n",
        "# Get Gradients of Loss WRT `features` input of Op #\n",
        "####################################################\n",
        "features_grad = trilinear_devoxelize_backward(dL_dout, inds, wgts, resolution)\n",
        "\n",
        "#####################\n",
        "# Print Out Tensors #\n",
        "#####################\n",
        "print(\"\\n\\n--------- Forward ---------\\n\")\n",
        "\n",
        "print(\"outs\\n----\")\n",
        "print(outs)\n",
        "print()\n",
        "\n",
        "print(\"\\ninds\\n----\")\n",
        "print(inds)\n",
        "print()\n",
        "\n",
        "print(\"wgts\\n----\")\n",
        "print(wgts)\n",
        "print()\n",
        "\n",
        "\n",
        "# print(\"--------- Backward ---------\\n\")\n",
        "\n",
        "print(\"dL/dout\\n------\")\n",
        "print(dL_dout)\n",
        "print()\n",
        "\n",
        "print(\"features graient\\n----------------\")\n",
        "print(features_grad)\n",
        "print(\"one batch\\n---------\")\n",
        "print(features_grad[0,:,:])\n",
        "print(\"\\n\")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--------- Forward ---------\n",
            "\n",
            "outs\n",
            "----\n",
            "tf.Tensor(\n",
            "[[[1. 2. 3. 4.]\n",
            "  [1. 2. 3. 4.]\n",
            "  [1. 2. 3. 4.]\n",
            "  [1. 2. 3. 4.]\n",
            "  [1. 2. 3. 4.]]\n",
            "\n",
            " [[1. 2. 3. 4.]\n",
            "  [1. 2. 3. 4.]\n",
            "  [1. 2. 3. 4.]\n",
            "  [1. 2. 3. 4.]\n",
            "  [1. 2. 3. 4.]]], shape=(2, 5, 4), dtype=float32)\n",
            "\n",
            "\n",
            "inds\n",
            "----\n",
            "tf.Tensor(\n",
            "[[[ 31  62  93 124]\n",
            "  [ 31  62  93 124]\n",
            "  [ 31  62  93 124]\n",
            "  [ 31  62  93 124]\n",
            "  [ 31  62  93 124]\n",
            "  [ 31  62  93 124]\n",
            "  [ 31  62  93 124]\n",
            "  [ 31  62  93 124]]\n",
            "\n",
            " [[ 31  62  93 124]\n",
            "  [ 31  62  93 124]\n",
            "  [ 31  62  93 124]\n",
            "  [ 31  62  93 124]\n",
            "  [ 31  62  93 124]\n",
            "  [ 31  62  93 124]\n",
            "  [ 31  62  93 124]\n",
            "  [ 31  62  93 124]]], shape=(2, 8, 4), dtype=int32)\n",
            "\n",
            "wgts\n",
            "----\n",
            "tf.Tensor(\n",
            "[[[1. 1. 1. 1.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]]\n",
            "\n",
            " [[1. 1. 1. 1.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]]], shape=(2, 8, 4), dtype=float32)\n",
            "\n",
            "dL/dout\n",
            "------\n",
            "tf.Tensor(\n",
            "[[[0.   0.05 0.1  0.15]\n",
            "  [0.   0.05 0.1  0.15]\n",
            "  [0.   0.05 0.1  0.15]\n",
            "  [0.   0.05 0.1  0.15]\n",
            "  [0.   0.05 0.1  0.15]]\n",
            "\n",
            " [[0.   0.05 0.1  0.15]\n",
            "  [0.   0.05 0.1  0.15]\n",
            "  [0.   0.05 0.1  0.15]\n",
            "  [0.   0.05 0.1  0.15]\n",
            "  [0.   0.05 0.1  0.15]]], shape=(2, 5, 4), dtype=float32)\n",
            "\n",
            "features graient\n",
            "----------------\n",
            "tf.Tensor(\n",
            "[[[0.   0.   0.   ... 0.   0.   0.15]\n",
            "  [0.   0.   0.   ... 0.   0.   0.15]\n",
            "  [0.   0.   0.   ... 0.   0.   0.15]\n",
            "  [0.   0.   0.   ... 0.   0.   0.15]\n",
            "  [0.   0.   0.   ... 0.   0.   0.15]]\n",
            "\n",
            " [[0.   0.   0.   ... 0.   0.   0.15]\n",
            "  [0.   0.   0.   ... 0.   0.   0.15]\n",
            "  [0.   0.   0.   ... 0.   0.   0.15]\n",
            "  [0.   0.   0.   ... 0.   0.   0.15]\n",
            "  [0.   0.   0.   ... 0.   0.   0.15]]], shape=(2, 5, 125), dtype=float32)\n",
            "one batch\n",
            "---------\n",
            "tf.Tensor(\n",
            "[[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.05 0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.1  0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.15]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.05 0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.1  0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.15]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.05 0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.1  0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.15]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.05 0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.1  0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.15]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.05 0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.1  0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.15]], shape=(5, 125), dtype=float32)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L139HrWrvLK",
        "outputId": "bf541157-d369-4354-a04d-20a87257e232"
      },
      "source": [
        "###################\n",
        "# Setup Constants #\n",
        "###################\n",
        "B = 2\n",
        "C = 5\n",
        "N = 4\n",
        "R = 4\n",
        "\n",
        "# [B, C, R**3] = [2, 5, 64]\n",
        "features = tf.constant([[\n",
        "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
        "   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0,\n",
        "   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3,]\n",
        "  ]], dtype=tf.float32)\n",
        "features = tf.repeat(tf.repeat(features, 5, axis=1), 2, axis=0)\n",
        "\n",
        "# [B, 3, N] = [2, 3, 4]\n",
        "coords = tf.constant([[[1, 2, 3, 4]]], dtype=tf.float32)\n",
        "coords = tf.repeat(tf.repeat(coords, 3, axis=1), 2, axis=0)\n",
        "\n",
        "# Attrs\n",
        "resolution = tf.constant(R)\n",
        "is_training = True\n",
        "\n",
        "##################\n",
        "# Call Operation #\n",
        "##################\n",
        "outs, inds, wgts = trilinear_devoxelize_forward(features, coords, resolution, is_training)\n",
        "\n",
        "#################################################\n",
        "# Get Gradients of Arbitrary Loss WRT Op Output #\n",
        "#################################################\n",
        "import time\n",
        "time.sleep(1)\n",
        "mse = tf.keras.losses.MeanSquaredError()\n",
        "ones_label = tf.ones(shape=[B, C, N])\n",
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(outs)\n",
        "  loss = mse(ones_label, outs)\n",
        "  dL_dout = tape.gradient(loss, outs)\n",
        "\n",
        "####################################################\n",
        "# Get Gradients of Loss WRT `features` input of Op #\n",
        "####################################################\n",
        "features_grad = trilinear_devoxelize_backward(dL_dout, inds, wgts, resolution)\n",
        "\n",
        "#####################\n",
        "# Print Out Tensors #\n",
        "#####################\n",
        "print(\"\\n\\n--------- Forward ---------\\n\")\n",
        "\n",
        "print(\"outs\\n----\")\n",
        "print(outs)\n",
        "print()\n",
        "\n",
        "print(\"\\ninds\\n----\")\n",
        "print(inds)\n",
        "print()\n",
        "\n",
        "print(\"wgts\\n----\")\n",
        "print(wgts)\n",
        "print()\n",
        "\n",
        "\n",
        "# print(\"--------- Backward ---------\\n\")\n",
        "\n",
        "print(\"dL/dout\\n------\")\n",
        "print(dL_dout)\n",
        "print()\n",
        "\n",
        "print(\"features graient\\n----------------\")\n",
        "print(features_grad)\n",
        "print(\"\\n\")\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--------- Forward ---------\n",
            "\n",
            "outs\n",
            "----\n",
            "tf.Tensor(\n",
            "[[[1. 2. 3. 0.]\n",
            "  [1. 2. 3. 0.]\n",
            "  [1. 2. 3. 0.]\n",
            "  [1. 2. 3. 0.]\n",
            "  [1. 2. 3. 0.]]\n",
            "\n",
            " [[1. 2. 3. 0.]\n",
            "  [1. 2. 3. 0.]\n",
            "  [1. 2. 3. 0.]\n",
            "  [1. 2. 3. 0.]\n",
            "  [1. 2. 3. 0.]]], shape=(2, 5, 4), dtype=float32)\n",
            "\n",
            "\n",
            "inds\n",
            "----\n",
            "tf.Tensor(\n",
            "[[[21 42 63 84]\n",
            "  [21 42 63 84]\n",
            "  [21 42 63 84]\n",
            "  [21 42 63 84]\n",
            "  [21 42 63 84]\n",
            "  [21 42 63 84]\n",
            "  [21 42 63 84]\n",
            "  [21 42 63 84]]\n",
            "\n",
            " [[21 42 63 84]\n",
            "  [21 42 63 84]\n",
            "  [21 42 63 84]\n",
            "  [21 42 63 84]\n",
            "  [21 42 63 84]\n",
            "  [21 42 63 84]\n",
            "  [21 42 63 84]\n",
            "  [21 42 63 84]]], shape=(2, 8, 4), dtype=int32)\n",
            "\n",
            "wgts\n",
            "----\n",
            "tf.Tensor(\n",
            "[[[1. 1. 1. 1.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]]\n",
            "\n",
            " [[1. 1. 1. 1.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]]], shape=(2, 8, 4), dtype=float32)\n",
            "\n",
            "dL/dout\n",
            "------\n",
            "tf.Tensor(\n",
            "[[[ 0.    0.05  0.1  -0.05]\n",
            "  [ 0.    0.05  0.1  -0.05]\n",
            "  [ 0.    0.05  0.1  -0.05]\n",
            "  [ 0.    0.05  0.1  -0.05]\n",
            "  [ 0.    0.05  0.1  -0.05]]\n",
            "\n",
            " [[ 0.    0.05  0.1  -0.05]\n",
            "  [ 0.    0.05  0.1  -0.05]\n",
            "  [ 0.    0.05  0.1  -0.05]\n",
            "  [ 0.    0.05  0.1  -0.05]\n",
            "  [ 0.    0.05  0.1  -0.05]]], shape=(2, 5, 4), dtype=float32)\n",
            "\n",
            "features graient\n",
            "----------------\n",
            "tf.Tensor(\n",
            "[[[ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.05  0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.1 ]\n",
            "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.   -0.05  0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.05  0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.1 ]\n",
            "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.   -0.05  0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.05  0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.1 ]\n",
            "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.   -0.05  0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.05  0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.1 ]\n",
            "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.   -0.05  0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.05  0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.1 ]]\n",
            "\n",
            " [[ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.   -0.05  0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.05  0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.1 ]\n",
            "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.   -0.05  0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.05  0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.1 ]\n",
            "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.   -0.05  0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.05  0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.1 ]\n",
            "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.   -0.05  0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.05  0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.1 ]\n",
            "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.   -0.05  0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.05  0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.1 ]]], shape=(2, 5, 64), dtype=float32)\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}